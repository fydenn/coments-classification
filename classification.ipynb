{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\glebp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\glebp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\glebp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>tonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401</td>\n",
       "      <td>4010201</td>\n",
       "      <td>826</td>\n",
       "      <td>2217</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>2,5 года работала и все...устала! Лампочка гор...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>403</td>\n",
       "      <td>4030101</td>\n",
       "      <td>1425</td>\n",
       "      <td>1026</td>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>Через 2 месяца после истечении гарантийного ср...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>401</td>\n",
       "      <td>4010401</td>\n",
       "      <td>124</td>\n",
       "      <td>2769</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>пользуюсь уже три недели. нареканий ни каких н...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>2030301</td>\n",
       "      <td>93</td>\n",
       "      <td>508</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>Ребят этот системный блок подойдёт для игры кс...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>2050201</td>\n",
       "      <td>656</td>\n",
       "      <td>1049</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>я считаю, что яри замечательный телефон! Прият...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_category  item_id  brand  user_id        date  \\\n",
       "0            401  4010201    826     2217  2013-06-28   \n",
       "1            403  4030101   1425     1026  2010-07-04   \n",
       "2            401  4010401    124     2769  2010-05-27   \n",
       "3            203  2030301     93      508  2016-10-11   \n",
       "4            205  2050201    656     1049  2010-02-26   \n",
       "\n",
       "                                             comment  rating  tonality  \n",
       "0  2,5 года работала и все...устала! Лампочка гор...     2.0  negative  \n",
       "1  Через 2 месяца после истечении гарантийного ср...     2.0  negative  \n",
       "2  пользуюсь уже три недели. нареканий ни каких н...     4.0  positive  \n",
       "3  Ребят этот системный блок подойдёт для игры кс...     5.0  positive  \n",
       "4  я считаю, что яри замечательный телефон! Прият...     5.0  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'market_comments.csv').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_to_0(ex):\n",
    "    return (0 if ex=='negative' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>tonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401</td>\n",
       "      <td>4010201</td>\n",
       "      <td>826</td>\n",
       "      <td>2217</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>2,5 года работала и все...устала! Лампочка гор...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>403</td>\n",
       "      <td>4030101</td>\n",
       "      <td>1425</td>\n",
       "      <td>1026</td>\n",
       "      <td>2010-07-04</td>\n",
       "      <td>Через 2 месяца после истечении гарантийного ср...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>401</td>\n",
       "      <td>4010401</td>\n",
       "      <td>124</td>\n",
       "      <td>2769</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>пользуюсь уже три недели. нареканий ни каких н...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>2030301</td>\n",
       "      <td>93</td>\n",
       "      <td>508</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>Ребят этот системный блок подойдёт для игры кс...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>2050201</td>\n",
       "      <td>656</td>\n",
       "      <td>1049</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>я считаю, что яри замечательный телефон! Прият...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_category  item_id  brand  user_id        date  \\\n",
       "0            401  4010201    826     2217  2013-06-28   \n",
       "1            403  4030101   1425     1026  2010-07-04   \n",
       "2            401  4010401    124     2769  2010-05-27   \n",
       "3            203  2030301     93      508  2016-10-11   \n",
       "4            205  2050201    656     1049  2010-02-26   \n",
       "\n",
       "                                             comment  rating  tonality  \n",
       "0  2,5 года работала и все...устала! Лампочка гор...     2.0         0  \n",
       "1  Через 2 месяца после истечении гарантийного ср...     2.0         0  \n",
       "2  пользуюсь уже три недели. нареканий ни каких н...     4.0         1  \n",
       "3  Ребят этот системный блок подойдёт для игры кс...     5.0         1  \n",
       "4  я считаю, что яри замечательный телефон! Прият...     5.0         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tonality'] = df['tonality'].apply(neg_to_0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14281 entries, 0 to 14280\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   item_category  14281 non-null  int64  \n",
      " 1   item_id        14281 non-null  int64  \n",
      " 2   brand          14281 non-null  int64  \n",
      " 3   user_id        14281 non-null  int64  \n",
      " 4   date           14281 non-null  object \n",
      " 5   comment        14281 non-null  object \n",
      " 6   rating         14281 non-null  float64\n",
      " 7   tonality       14281 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(2)\n",
      "memory usage: 892.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(f\"[{string.punctuation}]\", \" \", text)  \n",
    "    text = re.sub(r\"\\d+\", \" \", text)  \n",
    "    words = word_tokenize(text)  \n",
    "    words = [word for word in words if word not in stopwords.words('russian')]  \n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14281/14281 [00:02<00:00, 5446.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 2653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words = Counter()\n",
    "\n",
    "for example in tqdm(df.comment):\n",
    "    example = example.lower()\n",
    "    example = re.sub(f\"[{string.punctuation}]\", \"\", example)  \n",
    "    example = re.sub(r\"\\d+\", \"\", example)\n",
    "    for word in word_tokenize(example):\n",
    "        words[word] += 1\n",
    "\n",
    "vocab = set(['<unk>', '<bos>', '<eos>', '<pad>'])\n",
    "counter_threshold = 25\n",
    "\n",
    "for char, cnt in words.items():\n",
    "    if cnt > counter_threshold:\n",
    "        vocab.add(char)\n",
    "\n",
    "print(f'Размер словаря: {len(vocab)}')\n",
    "\n",
    "word2ind = {char: i for i, char in enumerate(vocab)}\n",
    "ind2word = {i: char for char, i in word2ind.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.unk_id = word2ind['<unk>']\n",
    "        self.bos_id = word2ind['<bos>']\n",
    "        self.eos_id = word2ind['<eos>']\n",
    "        self.pad_id = word2ind['<pad>']\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        processed_text = clean_text(self.data.iloc[idx].comment)\n",
    "        tokenized_sentence = [self.bos_id]\n",
    "        tokenized_sentence += [\n",
    "            word2ind.get(word, self.unk_id) for word in word_tokenize(processed_text)\n",
    "            ]\n",
    "        tokenized_sentence += [self.eos_id]\n",
    "\n",
    "        train_sample = {\n",
    "            \"text\": tokenized_sentence,\n",
    "            \"label\": self.data.iloc[idx].tonality\n",
    "        }\n",
    "\n",
    "        return train_sample\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_with_padding(\n",
    "        input_batch, pad_id=word2ind['<pad>'], max_len=128):\n",
    "   \n",
    "    seq_lens = [len(x['text']) for x in input_batch]\n",
    "    max_seq_len = min(max(seq_lens), max_len)\n",
    "\n",
    "    new_batch = []\n",
    "    for sequence in input_batch:\n",
    "        sequence['text'] = sequence['text'][:max_seq_len]\n",
    "        for _ in range(max_seq_len - len(sequence['text'])):\n",
    "            sequence['text'].append(pad_id)\n",
    "\n",
    "        new_batch.append(sequence['text'])\n",
    "\n",
    "    sequences = torch.LongTensor(new_batch).to(device)\n",
    "    labels = torch.LongTensor([x['label'] for x in input_batch]).to(device)\n",
    "\n",
    "    new_batch = {\n",
    "        'input_ids': sequences,\n",
    "        'label': labels\n",
    "    }\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.comment, df.tonality, test_size=0.8)\n",
    "\n",
    "train_data = pd.DataFrame({'comment': X_train, 'tonality': y_train})\n",
    "test_data = pd.DataFrame({'comment': X_test, 'tonality': y_test})\n",
    "\n",
    "train_dataset = WordDataset(train_data)\n",
    "test_dataset = WordDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLM(nn.Module):\n",
    "    def __init__(\n",
    "        self, hidden_dim: int, vocab_size: int, num_classes: int = 2\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.rnn = nn.RNN(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.projection = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.non_lin = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, input_batch) -> torch.Tensor:\n",
    "        embeddings = self.embedding(input_batch)  # [batch_size, seq_len, hidden_dim]\n",
    "        output, _ = self.rnn(embeddings)  # [batch_size, seq_len, hidden_dim]\n",
    "        output = output.mean(dim=1) #[batch_size, hidden_dim]\n",
    "        \n",
    "\n",
    "        output = self.dropout(self.linear(self.non_lin(output)))  # [batch_size, hidden_dim]\n",
    "        prediction = self.projection(self.non_lin(output))  # [batch_size, num_classes]\n",
    "\n",
    "        \n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLM(hidden_dim=256, vocab_size=len(vocab)).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2ind['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    test_dataset, shuffle=False, collate_fn=collate_fn_with_padding, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0434,  0.0107, -0.0612, -0.0611], device='cuda:0',\n",
      "       grad_fn=<MeanBackward1>) tensor([0, 1, 0, 1], device='cuda:0')\n",
      "tensor(0.6798, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataloader:\n",
    "    print(model(x['input_ids']).mean(dim=1), x['label'])\n",
    "    outp = model(x['input_ids'])\n",
    "    y = x['label']\n",
    "    print(criterion(outp, y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, loader):\n",
    "    acc = []\n",
    "    loss = []\n",
    "\n",
    "    for x,y in loader:\n",
    "        x = x.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     30\u001b[39m         optimizer.step()\n\u001b[32m     32\u001b[39m         epoch_losses.append(loss.item())\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_losses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_losses\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     35\u001b[39m     losses.append(\u001b[38;5;28msum\u001b[39m(epoch_losses) / \u001b[38;5;28mlen\u001b[39m(epoch_losses))\n\u001b[32m     37\u001b[39m losses_type[aggregation_type] = losses\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "num_epoch = 5\n",
    "eval_steps = len(train_dataloader) // 2\n",
    "\n",
    "\n",
    "losses_type = {}\n",
    "acc_type = {}\n",
    "\n",
    "for aggregation_type in ['max', 'mean']:\n",
    "    print(f\"Starting training for {aggregation_type}\")\n",
    "    losses = []\n",
    "    acc = []\n",
    "\n",
    "    model = CharLM(\n",
    "        hidden_dim=256, vocab_size=len(vocab), aggregation_type=aggregation_type).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=word2ind['<pad>'])\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        epoch_losses = []\n",
    "        model.train()\n",
    "        for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "\n",
    "            print(batch['input_ids'].size())\n",
    "            break\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch['input_ids'])\n",
    "            \n",
    "            loss = criterion(logits, batch['label'])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "        print(sum(epoch_losses) / len(epoch_losses))\n",
    "        losses.append(sum(epoch_losses) / len(epoch_losses))\n",
    "\n",
    "    losses_type[aggregation_type] = losses\n",
    "    acc_type[aggregation_type] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
